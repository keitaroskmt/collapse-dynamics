{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17060a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc37054",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_usr = \"your_wandb_username\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a21fb",
   "metadata": {},
   "source": [
    "### Fetch data from wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "project = f\"{wandb_usr}/collapse_dynamics\"\n",
    "weight_decays = [3e-1, 1e-1, 3e-2, 1e-2, 3e-3, 1e-3]\n",
    "seeds = [42, 43, 44, 45, 46]\n",
    "\n",
    "# Collect results for each run\n",
    "all_metrics = {\n",
    "    \"train_accuracy\": [],\n",
    "    \"test_accuracy\": [],\n",
    "    \"nc1_score\": [],\n",
    "    \"nc2_score\": [],\n",
    "    \"within_class_variance\": [],\n",
    "    \"scale_means\": [],\n",
    "    \"mi_zx_compression\": [],\n",
    "    \"mi_zy_compression\": [],\n",
    "    \"nhsic_zx\": [],\n",
    "    \"nhsic_zy\": [],\n",
    "    \"time_step\": [],\n",
    "}\n",
    "\n",
    "for weight_decay in weight_decays:\n",
    "    runs = api.runs(\n",
    "        path=project,\n",
    "        filters={\n",
    "            \"state\": \"finished\",\n",
    "            \"config.wandb.job_type\": \"change_weight_decay\",\n",
    "            \"config.optimizer.weight_decay\": weight_decay,\n",
    "            \"config.model.name\": \"toy_mlp\",\n",
    "            \"config.calc_nhsic\": True,\n",
    "        },\n",
    "        order=\"config.seed\",\n",
    "    )\n",
    "    run_metrics = {\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"nc1_score\": [],\n",
    "        \"nc2_score\": [],\n",
    "        \"within_class_variance\": [],\n",
    "        \"scale_means\": [],\n",
    "        \"mi_zx_compression\": [],\n",
    "        \"mi_zy_compression\": [],\n",
    "        \"nhsic_zx\": [],\n",
    "        \"nhsic_zy\": [],\n",
    "        \"time_step\": [],\n",
    "    }\n",
    "    for seed in seeds:\n",
    "        found = False\n",
    "        for run in runs:\n",
    "            if run.config[\"seed\"] != seed:\n",
    "                continue\n",
    "            df = run.history(pandas=True)\n",
    "            for key in run_metrics:\n",
    "                if np.any(df[key].to_numpy() == \"Infinity\"):\n",
    "                    print(\n",
    "                        f\"Weight decay {weight_decay} + seed {seed} contains infinity\",\n",
    "                    )\n",
    "                    break\n",
    "                if key in df:\n",
    "                    run_metrics[key].append(df[key].to_numpy())\n",
    "            found = True\n",
    "            break\n",
    "        if not found:\n",
    "            raise ValueError(\n",
    "                f\"Run with seed {seed} not found for weight decay {weight_decay}\",\n",
    "            )\n",
    "\n",
    "    # Align by time_step (assume all runs have the same time steps)\n",
    "    min_len = min(len(arr) for arr in run_metrics[\"time_step\"])\n",
    "    for key in run_metrics:\n",
    "        run_metrics[key] = [arr[:min_len] for arr in run_metrics[key]]\n",
    "        all_metrics[key].append(np.stack(run_metrics[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226c8ba",
   "metadata": {},
   "source": [
    "### Plot figures\n",
    "#### Figure showing grokking behaivor with different weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = list(plt.get_cmap(\"tab10\").colors[: len(weight_decays)])\n",
    "\n",
    "\n",
    "def first_cross(x, y, thr):\n",
    "    i = np.argmax(y >= thr)\n",
    "    return x[i] if y[i] >= thr else np.nan\n",
    "\n",
    "\n",
    "# Compute mean and std for each metric\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4), sharex=True)\n",
    "x = all_metrics[\"time_step\"][-1][0][:100000]  # time_step is the same for all seeds\n",
    "for i, weight_decay, color in zip(\n",
    "    range(len(weight_decays)),\n",
    "    weight_decays,\n",
    "    colors,\n",
    "    strict=False,\n",
    "):\n",
    "    data = all_metrics[\"train_accuracy\"][i]\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    axs[0].plot(x, mean, color=color, linestyle=\"--\", alpha=0.5, zorder=0)\n",
    "\n",
    "    data = all_metrics[\"test_accuracy\"][i]\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    axs[0].plot(x, mean, label=f\"$\\\\lambda = {weight_decay}$\", color=color)\n",
    "\n",
    "    data = all_metrics[\"within_class_variance\"][i] / (\n",
    "        all_metrics[\"scale_means\"][i] ** 2 + 1e-10\n",
    "    )\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    axs[1].plot(x, mean, label=f\"$\\\\lambda = {weight_decay}$\", color=color)\n",
    "\n",
    "    data = all_metrics[\"nc2_score\"][i]\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    axs[2].plot(x, mean, label=f\"$\\\\lambda = {weight_decay}$\", color=color)\n",
    "\n",
    "label_size = 13\n",
    "for i in range(3):\n",
    "    axs[i].set_xlabel(\"Time step\", fontsize=label_size)\n",
    "    axs[i].set_xlim(10, None)\n",
    "    axs[i].set_xscale(\"log\")\n",
    "    axs[i].grid()\n",
    "\n",
    "title_size = 15\n",
    "axs[0].set_title(\"Test Accuracy\", fontsize=title_size)\n",
    "axs[1].set_title(\"RNC1 Score\", fontsize=title_size)\n",
    "axs[2].set_title(\"NC2 Score\", fontsize=title_size)\n",
    "\n",
    "axs[0].legend(fontsize=11, loc=\"upper left\")\n",
    "axs[1].legend(fontsize=11, loc=\"lower left\")\n",
    "axs[2].legend(fontsize=11, loc=\"lower left\")\n",
    "\n",
    "axs[2].set_ylim(0, None)\n",
    "axs[2].set_yticks([1 if x == 0 else x for x in axs[2].get_yticks()])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59911b26",
   "metadata": {},
   "source": [
    "#### Figure showing IB dynamics with different weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6995fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = list(plt.get_cmap(\"tab10\").colors[: len(weight_decays)])\n",
    "\n",
    "\n",
    "def first_cross(x, y, thr):\n",
    "    i = np.argmax(y >= thr)\n",
    "    return x[i] if y[i] >= thr else np.nan\n",
    "\n",
    "\n",
    "# Compute mean and std for each metric\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4), sharex=True)\n",
    "x = all_metrics[\"time_step\"][-1][0][:100000]  # time_step is the same for all seeds\n",
    "for i, weight_decay, color in zip(\n",
    "    range(len(weight_decays)),\n",
    "    weight_decays,\n",
    "    colors,\n",
    "    strict=False,\n",
    "):\n",
    "    data = all_metrics[\"mi_zx_compression\"][i] - all_metrics[\"mi_zy_compression\"][i]\n",
    "    mean = data.mean(axis=0)\n",
    "    axs[0].plot(x, mean, label=f\"$\\\\lambda = {weight_decay}$\", color=color)\n",
    "\n",
    "    data = all_metrics[\"nhsic_zx\"][i] - all_metrics[\"nhsic_zy\"][i]\n",
    "    mean = data.mean(axis=0)\n",
    "    axs[1].plot(x, mean, label=f\"$\\\\lambda = {weight_decay}$\", color=color)\n",
    "\n",
    "    data = all_metrics[\"within_class_variance\"][i] / (\n",
    "        all_metrics[\"scale_means\"][i] ** 2 + 1e-10\n",
    "    )\n",
    "    mean = data.mean(axis=0)\n",
    "    axs[2].plot(x, mean, label=f\"$\\\\lambda = {weight_decay}$\", color=color)\n",
    "\n",
    "label_size = 13\n",
    "for i in range(3):\n",
    "    axs[i].set_xlabel(\"Time step\", fontsize=label_size)\n",
    "    axs[i].set_xlim(10, None)\n",
    "    axs[i].set_xscale(\"log\")\n",
    "    axs[i].grid()\n",
    "\n",
    "title_size = 15\n",
    "axs[0].set_title(\"$\\\\hat{I}(Z;X) - \\\\hat{I}(Z;Y)$\", fontsize=title_size)\n",
    "axs[1].set_title(\"$\\\\text{nHSIC}(Z;X) - \\\\text{nHSIC}(Z;Y)$\", fontsize=title_size)\n",
    "axs[2].set_title(\"RNC1 Score\", fontsize=title_size)\n",
    "\n",
    "axs[0].legend(fontsize=11, loc=\"lower left\")\n",
    "axs[1].legend(fontsize=11, loc=\"lower left\")\n",
    "axs[2].legend(fontsize=11, loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cac83e",
   "metadata": {},
   "source": [
    "### Figure showing margins of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b53f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import Tensor, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_features(\n",
    "    model: nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    model.eval()\n",
    "    features, labels = [], []\n",
    "    for data, target in loader:\n",
    "        forward_result = model(data, return_repr=True)\n",
    "        features.append(forward_result.representation)\n",
    "        labels.append(target)\n",
    "    features = torch.cat(features, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def get_classifier_weights_and_biases(model: nn.Module) -> tuple[Tensor, Tensor]:\n",
    "    classifier = model.last_layer\n",
    "    if not isinstance(classifier, nn.Linear):\n",
    "        msg = \"The last layer of the model must be a linear layer.\"\n",
    "        raise TypeError(msg)\n",
    "    w = classifier.weight.detach().cpu()\n",
    "    b = classifier.bias.detach().cpu()\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def get_orthogonal_basis_from_weights(\n",
    "    weight: Tensor,\n",
    "    class_1: int,\n",
    "    class_2: int,\n",
    ") -> Tensor:\n",
    "    \"\"\"Get an orthogonal basis from the weights of two classes.\n",
    "\n",
    "    Returns: Tensor of shape (2, D) where D is the dimension of the weights.\n",
    "    \"\"\"\n",
    "    if not (0 <= class_1 < weight.shape[0] and 0 <= class_2 < weight.shape[0]):\n",
    "        msg = \"class_1 and class_2 must be valid class indices.\"\n",
    "        raise ValueError(msg)\n",
    "    w1 = weight[class_1]\n",
    "    w2 = weight[class_2]\n",
    "    e1 = (w1 - w2) / ((w1 - w2).norm() + 1e-12)\n",
    "    w2_orth = w2 - e1 * (w2 @ e1)\n",
    "    if w2_orth.norm() < 1e-12:  # noqa: PLR2004\n",
    "        msg = \"The two classes are not linearly separable.\"\n",
    "        raise ValueError(msg)\n",
    "    e2 = w2_orth / (w2_orth.norm() + 1e-12)\n",
    "    return torch.stack([e1, e2], dim=0)\n",
    "\n",
    "\n",
    "def plot_decision_boundary_with_two_classes(\n",
    "    ax: plt.Axes,\n",
    "    w: Tensor,\n",
    "    b: Tensor,\n",
    "    class_1: int,\n",
    "    class_2: int,\n",
    ") -> None:\n",
    "    w1, w2 = w[class_1], w[class_2]\n",
    "    b1, b2 = b[class_1], b[class_2]\n",
    "\n",
    "    x = (b2 - b1) / ((w1 - w2).norm() + 1e-12)\n",
    "    ylim = ax.get_ylim()\n",
    "    ys = np.linspace(ylim[0], ylim[1], 1000)\n",
    "    ax.plot(x * np.ones_like(ys), ys)\n",
    "\n",
    "\n",
    "def plot_violin_with_two_classes(  # noqa: PLR0913\n",
    "    model: nn.Module,\n",
    "    features: Tensor,\n",
    "    labels: Tensor,\n",
    "    ax: plt.Axes,\n",
    "    class_1: int,\n",
    "    class_2: int,\n",
    "    label_size: int = 12,\n",
    ") -> None:\n",
    "    w, b = get_classifier_weights_and_biases(model)\n",
    "    w1, w2 = w[class_1], w[class_2]\n",
    "    b1, b2 = b[class_1], b[class_2]\n",
    "    scores = (features @ (w1 - w2) + (b2 - b1)) / (torch.norm(w1 - w2) + 1e-12)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"score\": scores,\n",
    "            \"class\": pd.Series(labels).map(\n",
    "                {class_1: f\"class {class_1}\", class_2: f\"class {class_2}\"},\n",
    "            ),\n",
    "            \"axis\": \"baseline\",\n",
    "        },\n",
    "    )\n",
    "    sns.violinplot(\n",
    "        x=\"score\",\n",
    "        y=\"axis\",\n",
    "        hue=\"class\",\n",
    "        hue_order=[f\"class {class_1}\", f\"class {class_2}\"],\n",
    "        data=df,\n",
    "        ax=ax,\n",
    "        split=True,\n",
    "        density_norm=\"area\",\n",
    "        inner=\"quartile\",\n",
    "        palette=sns.color_palette(\"tab10\", n_colors=2),\n",
    "        bw_adjust=0.8,\n",
    "        linewidth=0.8,\n",
    "        common_norm=True,\n",
    "    )\n",
    "    ax.set_xbound(-2.2, 2.2)\n",
    "    ax.axvline(0, color=\"black\", linestyle=\"-\")\n",
    "    ax.set_xlabel(\n",
    "        rf\"Signed distance to decision boundary (class {class_1} vs. class {class_2})\",\n",
    "        fontsize=label_size,\n",
    "    )\n",
    "    ax.set_ylabel(\"Density\", fontsize=label_size)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.legend()\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b62880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loader\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "\n",
    "train_size = 1000\n",
    "\n",
    "image_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "    ],\n",
    ")\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/pytorch_datasets\",\n",
    "    train=True,\n",
    "    transform=image_transform,\n",
    "    download=True,\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"~/pytorch_datasets\",\n",
    "    train=False,\n",
    "    transform=image_transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "train_dataset = Subset(train_dataset, range(train_size))\n",
    "train_unseen_dataset = Subset(train_dataset, range(train_size, len(train_dataset)))\n",
    "combined_dataset = ConcatDataset([train_unseen_dataset, test_dataset])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "unseen_loader = DataLoader(combined_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19823dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.toy_mlp import MLPModel\n",
    "\n",
    "model = MLPModel()\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"~/collapse-dynamics/saved_models/toy_mlp/mnist/model_step_99900.pt\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "f_train, l_train = get_features(model, train_loader)\n",
    "f_unseen, l_unseen = get_features(model, unseen_loader)\n",
    "\n",
    "class_1, class_2 = 0, 1  # Example classes to visualize\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 2.5), sharex=True)\n",
    "plot_violin_with_two_classes(model, f_train, l_train, axs[0], class_1, class_2)\n",
    "plot_violin_with_two_classes(model, f_unseen, l_unseen, axs[1], class_1, class_2)\n",
    "\n",
    "axs[0].set_title(\"Train Examples\", fontsize=15)\n",
    "axs[1].set_title(\"Unseen Examples\", fontsize=15)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collapse-dynamics (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
